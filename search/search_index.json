{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the docs for RLM Booking","text":""},{"location":"#david-hu-alex-yung-andy-zeng-cody-liddle-michael-li-eli-sterling","title":"David Hu, Alex Yung, Andy Zeng, Cody Liddle, Michael Li, Eli Sterling","text":"<p>Select an item in the table of contents on the left to get started.</p>"},{"location":"aws/ci_cd_deployment/","title":"CI/CD and Deployment","text":"<p>This document covers our process to set up Continuous Integration and Continuous Deployment (CI/CD) pipelines to streamline application updates and maintain consistency.</p>"},{"location":"aws/ci_cd_deployment/#a-aws-codepipeline-and-codebuild","title":"A. AWS CodePipeline and CodeBuild","text":""},{"location":"aws/ci_cd_deployment/#purpose","title":"Purpose","text":"<ul> <li>To automate code deployment and ensure consistent updates to AWS resources (e.g., Lambda functions, SageMaker models).</li> </ul>"},{"location":"aws/ci_cd_deployment/#setup-steps","title":"Setup Steps","text":"<ol> <li> <p>Create a CodePipeline:</p> <ol> <li>Connect CodePipeline to the project\u2019s Git repository (e.g., GitHub).</li> <li>Define stages: Source (from Git), Build (CodeBuild), and Deploy (to relevant AWS services).</li> </ol> </li> <li> <p>CodeBuild Configuration:</p> <ol> <li>Set up a build environment with the necessary dependencies (e.g., Python for Lambda, PySpark for Glue jobs).</li> <li>Use buildspec files to specify build commands and output artifacts.</li> </ol> </li> </ol>"},{"location":"aws/ci_cd_deployment/#b-automating-infrastructure-deployment","title":"B. Automating Infrastructure Deployment","text":"<ol> <li> <p>AWS CloudFormation:</p> <ol> <li>Use CloudFormation templates to define and deploy infrastructure as code.</li> <li>Store templates in the version control system for easy access and reuse.</li> </ol> </li> <li> <p>Infrastructure-as-Code (IaC):</p> <ol> <li>Codify the infrastructure setup to ensure that future developers can replicate the environment.</li> <li>(I'll finish later)</li> </ol> </li> </ol>"},{"location":"aws/ci_cd_deployment/#c-testing-and-deployment","title":"C. Testing and Deployment","text":"<ol> <li> <p>Test Lambda Functions and API Endpoints:</p> <ul> <li>Use the AWS Console to test functions directly and ensure the API Gateway endpoints function as expected.</li> </ul> </li> <li> <p>Deploy to Production:</p> <ul> <li>Use CodePipeline to push updates to Production after Development testing.</li> </ul> </li> </ol>"},{"location":"aws/core_aws_resources/","title":"Core AWS Resources","text":"<p>This section details the core AWS resources my team set up and how for the client project, covering storage, processing, and machine learning components. It covers the high level design choices we made, why, and our basic configuration to get an idea of our general direction. </p>"},{"location":"aws/core_aws_resources/#a-data-storage-and-management","title":"A. Data Storage and Management","text":""},{"location":"aws/core_aws_resources/#amazon-dynamodb","title":"Amazon DynamoDB","text":"<ul> <li>Purpose: Fast, scalable storage for structured data.</li> <li> <p>Relation to Project:</p> <ul> <li>Includes tables such as <code>Artists</code>, <code>Venues</code>, <code>Events</code>.</li> <li>Configured Read/Write Capacity as needed. DynamoDB will scale automatically.</li> </ul> </li> </ul>"},{"location":"aws/core_aws_resources/#amazon-s3","title":"Amazon S3","text":"<ul> <li>Purpose: Stores unstructured data (e.g., images, reports).</li> <li> <p>Relation to Project:</p> <ul> <li>Includes buckets like <code>rlm-prod-artist-data</code>, <code>rlm-dev-event-reports</code>.</li> <li>Enabled versioning for data tracking.</li> </ul> </li> </ul>"},{"location":"aws/core_aws_resources/#b-data-processing-and-machine-learning","title":"B. Data Processing and Machine Learning","text":""},{"location":"aws/core_aws_resources/#aws-sagemaker","title":"AWS SageMaker","text":"<ul> <li>Purpose: For training recommendation models and deploying them.</li> <li> <p>Relation to Project:</p> <ul> <li>Deployed a Notebook Instance for data exploration and model training.</li> <li>Deployed trained models as endpoints for real-time recommendations.</li> </ul> </li> </ul>"},{"location":"aws/core_aws_resources/#aws-glue-etl","title":"AWS Glue (ETL)","text":"<ul> <li>Purpose: Data preparation tasks (e.g., cleaning data from external sources).</li> <li> <p>Relation to Project:</p> <ul> <li>Went to Glue in the AWS Console.</li> <li>Created Jobs and Crawlers to extract, transform, and load data into DynamoDB or S3.</li> </ul> </li> </ul>"},{"location":"aws/core_aws_resources/#c-api-and-serverless-compute","title":"C. API and Serverless Compute","text":""},{"location":"aws/core_aws_resources/#aws-lambda","title":"AWS Lambda","text":"<ul> <li>Purpose: Serverless backend processes for handling real-time requests.</li> <li> <p>Relation to Project:</p> <ul> <li>Created functions for specific tasks (e.g., <code>RecommendArtist</code>, <code>FetchEventAnalytics</code>).</li> <li>Connected Lambda functions to DynamoDB or SageMaker endpoints as needed.</li> </ul> </li> </ul>"},{"location":"aws/core_aws_resources/#api-gateway","title":"API Gateway","text":"<ul> <li>Purpose: Creates RESTful APIs for frontend or external integration.</li> <li> <p>Relation to Project:</p> <ul> <li>Created an API and define endpoints (e.g., <code>/recommend</code>, <code>/analyze</code>, <code>/fetch-trends</code>).</li> </ul> </li> </ul>"},{"location":"aws/core_aws_resources/#d-monitoring-and-logging","title":"D. Monitoring and Logging","text":""},{"location":"aws/core_aws_resources/#amazon-cloudwatch","title":"Amazon CloudWatch","text":"<ul> <li>Purpose: To monitor application metrics, setting alarms, and creating logs for AWS resources we used like Lambda and SageMaker.</li> <li> <p>Relation to Project:</p> <ul> <li> <p>Alarms:</p> <ul> <li>Create CloudWatch Alarms for critical metrics (e.g., Lambda function errors, SageMaker model performance).</li> <li>Configure alarms to notify via Amazon SNS for immediate response.</li> </ul> </li> <li> <p>Logs:</p> <ul> <li>Enable logs for each Lambda function to track runtime data and troubleshoot errors.</li> <li>For model monitoring, set up logs in SageMaker to track model performance over time.</li> </ul> </li> </ul> </li> </ul>"},{"location":"aws/core_aws_resources/#quicksight","title":"QuickSight","text":"<ul> <li> <p>Purpose: QuickSight can be used for visualizing analytics and historical data, creating BI dashboards if reporting is required.</p> </li> <li> <p>Relation to Project</p> <ul> <li> <p>Data Sources:</p> <ul> <li>Connect QuickSight to S3, DynamoDB, or RDS as needed.</li> </ul> </li> <li> <p>Create Dashboards:</p> <ul> <li>Develop dashboards for key metrics (e.g., ticket sales, event performance, artist popularity).</li> <li>Use visualizations to gain insights into data trends.</li> </ul> </li> </ul> </li> </ul>"},{"location":"aws/iam_permissions/","title":"IAM and Permissions","text":"<p>This document provides an overview my team's IAM roles and permissions. The aim is to build secure, role-based access control for each member of the project.</p>"},{"location":"aws/iam_permissions/#a-role-based-access-control-rbac","title":"A. Role-Based Access Control (RBAC)","text":""},{"location":"aws/iam_permissions/#purpose","title":"Purpose","text":"<ul> <li>IAM roles specific to each team member's function ensures controlled access to resources.</li> </ul>"},{"location":"aws/iam_permissions/#role-assignments","title":"Role Assignments","text":"<ul> <li> <p>Project Manager Role: Full administrative access for oversight and management.</p> <ul> <li>Assigned to: David</li> <li>Permissions: Full access to all AWS resources for project oversight.</li> </ul> </li> <li> <p>Business Analyst Role: Limited access for data reporting and analysis.</p> <ul> <li>Assigned to: Eli</li> <li>Permissions: Access to Amazon QuickSight, Athena, and read-only permissions for DynamoDB and S3.</li> </ul> </li> <li> <p>Front End Developer Role: Access for front-end assets and API invocation.</p> <ul> <li>Assigned to: Alex</li> <li>Permissions: Read-only access to S3 for assets, view-only access to Lambda functions, and API Gateway invocation permissions.</li> </ul> </li> <li> <p>Back End Developer Role: Full backend operations access.</p> <ul> <li>Assigned to: Michael</li> <li>Permissions: Full access to Lambda, RDS, API Gateway, and DynamoDB as needed.</li> </ul> </li> <li> <p>Data Scientist Role: Permissions for model development and data processing.</p> <ul> <li>Assigned to: Cody</li> <li>Permissions: Full access to SageMaker, Glue, read-only access to DynamoDB, and S3 for data storage.</li> </ul> </li> <li> <p>Data Engineer Role: Data ingestion and transformation permissions.</p> <ul> <li>Assigned to: Andy</li> <li>Permissions: Full access to Glue, Kinesis, S3, and optional DynamoDB for data management.</li> </ul> </li> </ul>"},{"location":"aws/iam_permissions/#b-iam-groups-and-policies","title":"B. IAM Groups and Policies","text":"<ul> <li> <p>DevTeam Group:</p> <ul> <li>All developers are part of the <code>DevTeam</code> IAM group, which includes shared permissions like CloudWatch read-only access and S3 read-only access.</li> </ul> </li> <li> <p>Temporary Credentials and Assume Role:</p> <ul> <li>I Encouraged my team's developers to use temporary credentials by assuming roles with AWS CLI or SDK to minimize long-term credential exposure.</li> </ul> </li> </ul>"},{"location":"aws/iam_permissions/#c-secrets-management","title":"C. Secrets Management","text":"<ul> <li> <p>Used AWS Secrets Manager:</p> <ul> <li>We used Secrets Manager to store sensitive API keys or credentials securely.</li> </ul> </li> <li> <p>How we Accessed Secrets Programmatically:</p> <ul> <li>We used SDKs (e.g., Python's boto3) to fetch secrets securely in application code.</li> </ul> </li> </ul>"},{"location":"aws/migration_elastic_beanstalk/","title":"Migration and Elastic Beanstalk Planning","text":"<p>This document outlines my plan for a phased approach to adding a frontend using AWS Elastic Beanstalk to ensure a smooth migration and integration with existing backend components.</p>"},{"location":"aws/migration_elastic_beanstalk/#a-elastic-beanstalk-overview","title":"A. Elastic Beanstalk Overview","text":""},{"location":"aws/migration_elastic_beanstalk/#purpose","title":"Purpose","text":"<ul> <li>Elastic Beanstalk will host a future frontend app, integrating seamlessly with existing AWS services (e.g., DynamoDB, Lambda, SageMaker).</li> </ul>"},{"location":"aws/migration_elastic_beanstalk/#setup-steps","title":"Setup Steps","text":"<ol> <li> <p>API Gateway Integration:</p> <ul> <li>Use the existing API Gateway endpoints to connect the frontend with backend functionality.</li> </ul> </li> <li> <p>Web App Components:</p> <ul> <li>Deploy the frontend, a React app in our case, on Elastic Beanstalk, and connect it to API Gateway for seamless interaction with backend services.</li> </ul> </li> </ol>"},{"location":"aws/migration_elastic_beanstalk/#b-preparing-for-migration","title":"B. Preparing for Migration","text":"<ol> <li> <p>Set Up REST APIs:</p> <ul> <li>Set up RESTful APIs with API Gateway and Lambda for core functions, allowing frontend access without reconfiguring backend.</li> </ul> </li> <li> <p>Organize Data and Resources with Tags:</p> <ul> <li>Use the tag resources by feature (e.g., <code>Feature: Modeling</code>, <code>Feature: Event Management</code>) for easier tracking and future migration planning.</li> </ul> </li> </ol>"},{"location":"aws/migration_elastic_beanstalk/#c-cicd-pipeline-for-frontend-integration","title":"C. CI/CD Pipeline for Frontend Integration","text":"<ol> <li> <p>Add Frontend Deployment to CodePipeline:</p> <ul> <li>Extend CodePipeline to automate deployment for both backend and frontend services.</li> </ul> </li> <li> <p>Consistent Logging and Monitoring:</p> <ul> <li>Use CloudWatch to monitor performance and troubleshoot any frontend integration issues.</li> </ul> </li> </ol>"},{"location":"aws/organization_outline/","title":"AWS Setup and Organization for Client Project","text":"<p>This document covers my team's initial organizational structure outline to deploy AWS resources efficiently across development and production environments. Specifics on how each team member fits in this structure can be found in iam_permissions.md.</p>"},{"location":"aws/organization_outline/#aws-systems-manager-application-manager","title":"AWS Systems Manager - Application Manager","text":"<ul> <li>Path: AWS Management Console &gt; Systems Manager &gt; Application Manager.</li> <li> <p>Steps:</p> <ol> <li>Create New Application: Name it based on the project (e.g., <code>ArtistRecommenderApp</code>). We named ours <code>RLM_Booking</code>.</li> <li>Tagging: Our tags were <code>Client: RLM</code>, <code>Project: Booking</code>, <code>Environment: Developer</code> and <code>Environment: Production</code> in the setup. The point is to organize the application, there's room to add more necessary tags later.</li> </ol> </li> </ul> <p>Purpose: The Application Manager provides a high-level view of resources and configurations tied to this specific client project.</p>"},{"location":"aws/organization_outline/#environment-separation","title":"Environment Separation","text":"<ul> <li>Development and Production environments should be isolated to avoid data and configuration conflicts.</li> </ul>"},{"location":"aws/organization_outline/#environment-specific-resources","title":"Environment-Specific Resources","text":"<ul> <li>Created separate resources per environment (e.g., different S3 buckets, Lambda functions, databases).</li> <li>Used tags like <code>Environment: Development</code> and <code>Environment: Production</code> to distinguish between them.</li> </ul>"},{"location":"aws/organization_outline/#access-control","title":"Access Control","text":"<ul> <li>Restricted Production access to specific team members.</li> <li>Development resources can have broader access for testing purposes.</li> </ul>"},{"location":"aws/organization_outline/#use-of-aws-organizations-for-multi-client-management","title":"Use of AWS Organizations for Multi-Client Management","text":""},{"location":"aws/organization_outline/#dedicated-aws-account","title":"Dedicated AWS Account","text":"<ul> <li>Purpose: Keeps resources, billing, and permissions isolated.</li> <li>Recommendation Outside this Project Scope: AWS Organizations is used for managing multiple clients. This allows for consistent policies and centralized billing management. BAI Exec will have access to the AWS Organization that your AWS Account (not your personal, the client one) is managed by.</li> </ul>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>This guide details the configuration settings and environment variables required to run the project. Make sure these are set correctly to ensure smooth operation in both development and production environments.</p>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":"<p>The following environment variables should be added to the <code>.env</code> files for both the backend (Django) and frontend (React) applications.</p>"},{"location":"getting-started/configuration/#backend-env-in-root-directory","title":"Backend (.env in root directory)","text":"<ol> <li>DJANGO_SECRET_KEY: Secret key for Django's cryptographic signing.</li> <li> <p>Example: <code>DJANGO_SECRET_KEY=your_secret_key</code></p> </li> <li> <p>DATABASE_URL: URL connection string for the database.</p> </li> <li> <p>Example: <code>DATABASE_URL=postgres://username:password@localhost:5432/database_name</code></p> </li> <li> <p>AWS_ACCESS_KEY_ID: AWS access key for cloud services.</p> </li> <li> <p>Example: <code>AWS_ACCESS_KEY_ID=your_aws_key</code></p> </li> <li> <p>AWS_SECRET_ACCESS_KEY: AWS secret access key for cloud services.</p> </li> <li> <p>Example: <code>AWS_SECRET_ACCESS_KEY=your_aws_secret</code></p> </li> <li> <p>OTHER_BACKEND_VARIABLES: [For future env variables, with examples and explanations.]</p> </li> </ol>"},{"location":"getting-started/configuration/#frontend-env-in-frontend-directory","title":"Frontend (.env in <code>frontend</code> directory)","text":"<ol> <li>REACT_APP_API_URL: URL for the backend API to connect to the Django server.</li> <li> <p>Example: <code>REACT_APP_API_URL=http://localhost:8000/api</code></p> </li> <li> <p>OTHER_FRONTEND_VARIABLES: [Future frontend-specific variables here, if applicable.]</p> </li> </ol>"},{"location":"getting-started/configuration/#configuration-files","title":"Configuration Files","text":"<p>In addition to environment variables, the project may use specific configuration files. Here are the key ones: (none right now)</p>"},{"location":"getting-started/configuration/#django-settings","title":"Django Settings","text":"<ul> <li>settings.py: Modify settings for database connection, installed apps, middleware, and other configurations.</li> <li>Ensure <code>ALLOWED_HOSTS</code> includes your development and production domains.</li> <li>Set <code>DEBUG = True</code> for development and <code>DEBUG = False</code> for production.</li> </ul>"},{"location":"getting-started/configuration/#aws-cli-configuration","title":"AWS CLI Configuration","text":"<p>To interact with AWS services, the AWS CLI must be configured with access credentials:</p> <ol> <li>Run <code>aws configure</code> in the terminal and enter:</li> <li>Access Key ID</li> <li>Secret Access Key</li> <li> <p>Default Region</p> </li> <li> <p>Check <code>~/.aws/credentials</code> if you need to review your AWS configuration.</p> </li> </ol>"},{"location":"getting-started/configuration/#docker-configuration-for-production","title":"Docker Configuration (for Production)","text":"<p>Docker may be used in the future for production. Configuration files will be provided, and steps to build and run Docker containers will be updated here.</p>"},{"location":"getting-started/configuration/#additional-notes","title":"Additional Notes","text":"<ul> <li>Storing Secrets Securely: For production, avoid hardcoding secrets in code. Use a secure secret management service (we use AWS Secrets Manager) if available.</li> <li>Configuration Updates: Whenever a configuration change is made, update this document and any corresponding <code>.env</code> files to maintain accurate setup instructions. If you have write access to the repository then this will be updated with your changes every git commit to github (updates via github pages).</li> </ul>"},{"location":"getting-started/installation-guide/","title":"Installation Guide","text":"<p>This guide provides step-by-step instructions to set up the project for local development.</p>"},{"location":"getting-started/installation-guide/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the following installed on your machine:</p> <ul> <li>Python (version 3.12)</li> <li>Node.js (version 22.11.0) and npm</li> <li>AWS CLI (for cloud services interaction)</li> <li>Docker ([will populate in the future when we do production])</li> </ul>"},{"location":"getting-started/installation-guide/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<p>Clone the project repository from GitHub:</p> <pre><code>git clone https://github.com/dhu2022-dev/RLM-Booking.git\ncd yourproject\n</code></pre>"},{"location":"getting-started/installation-guide/#step-2-set-up-backend-django","title":"Step 2: Set Up Backend (Django)","text":"<ol> <li> <p>Create a Virtual Environment:</p> <p><code>bash python -m venv venv source venv/bin/activate  # On Windows, use `venv\\Scripts\\activate`</code></p> </li> <li> <p>Install Dependencies:</p> <p>Install the required Python packages listed in <code>requirements.txt</code>:</p> <p><code>bash pip install -r requirements.txt</code></p> </li> <li> <p>Configure Environment Variables:</p> <p>Create a <code>.env</code> file in the root directory with the following variables:</p> <p><code>env DJANGO_SECRET_KEY=your_secret_key DATABASE_URL=your_database_url AWS_ACCESS_KEY_ID=your_aws_key AWS_SECRET_ACCESS_KEY=your_aws_secret REGION_NAME=your-db-region# TABLE_NAME=your_table_name SPOTIFY_CLIENT_ID=your_spotify_client_id SPOTIFY_CLIENT_SECRET=your_spotify_client_secret TICKETMASTER_API_KEY=your_ticketmaster_api_key TICKETMASTER_API_SECRET=your_ticketmaster_api_secret</code></p> <p>See configuration documentation for specific examples and additional info on this.</p> </li> <li> <p>Apply Migrations:</p> <p>Set up the database by running migrations:</p> <p><code>bash python manage.py migrate</code></p> </li> <li> <p>Run the Development Server:</p> <p>Start the Django server:</p> <p><code>bash python manage.py runserver</code></p> </li> </ol>"},{"location":"getting-started/installation-guide/#step-3-set-up-frontend-react-do-not-worry-about-this-for-now","title":"Step 3: Set up Frontend (React) DO NOT WORRY ABOUT THIS FOR NOW","text":"<ol> <li> <p>Navigate to the Frontend Directory:</p> <p><code>bash cd frontend</code></p> </li> <li> <p>Install Dependencies:</p> <p>Use npm to install the necessary packages:</p> <p><code>bash npm install</code></p> </li> <li> <p>Configure Environment Variables:</p> <p>Create a .env file in the frontend directory with any frontend-specific environment variables:</p> <p><code>bash REACT_API_API_URL=http://localhost:8000/api</code></p> </li> <li> <p>Run the Development Server:</p> <p>Start the React development server:</p> <p><code>bash npm start</code></p> </li> </ol>"},{"location":"getting-started/installation-guide/#step-4-set-up-cloud-services-aws","title":"Step 4: Set up Cloud Services (AWS)","text":"<p>To connect to AWS resources:</p> <ol> <li> <p>Configure AWS CLI: Set up AWS credentials:</p> <p><code>bash aws configure</code></p> <p>Enter your AWS Access Key ID, Secret Access Key, and default region.</p> </li> <li> <p>Verify S3 and DynamoDB Access:</p> <p>Ensure you have the correct permissions for S3 and DynamoDB. Contact who.is.david101@gmail.com for AWS Permissions if you are a developer for Red Light.</p> </li> </ol>"},{"location":"getting-started/installation-guide/#step-5-running-the-application","title":"Step 5: Running the Application","text":"<p>With both Django backend and React frontend running, you can access the application at:</p> <ul> <li>Frontend: http://localhost:3000</li> <li>Backend: http://localhost:8000</li> </ul>"},{"location":"getting-started/installation-guide/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Common Issues:</li> <li>[Put stuff people struggle with here]</li> </ul>"},{"location":"introduction/project-overview/","title":"Project Overview","text":""},{"location":"introduction/project-overview/#purpose","title":"Purpose","text":"<p>The purpose of this project is to develop an AI-powered application for Red Light Ventures, a mid-sized concert venue, to enhance their performance in booking, managing, and marketing shows. The application leverages data and machine learning to streamline event management and provide actionable insights for better decision-making.</p>"},{"location":"introduction/project-overview/#key-technologies","title":"Key Technologies","text":"<ul> <li>Backend: Django (Python)</li> <li>Frontend: React (JavaScript, HTML/CSS)</li> <li>Cloud Infrastructure: AWS (Sagemaker, DynamoDB, S3, EC2)</li> </ul>"},{"location":"introduction/project-overview/#goals","title":"Goals","text":"<p>The app is designed to help Red Light Ventures achieve the following objectives:</p> <ul> <li>Optimized Event Management: Efficiently manage and schedule events to maximize attendance and profitability.</li> <li>Ticket Pricing Insights: Use AI to dynamically recommend optimal ticket pricing based on demand, event popularity, and audience data.</li> <li>Booking Recommendations: Identify high-potential shows and artists in the area to book, helping attract larger audiences.</li> <li>Concert Performance Analysis: Analyze past concert performance to understand what drives successful events.</li> <li>Targeted Marketing: Provide data-driven insights to improve show promotion and audience engagement.</li> </ul>"},{"location":"introduction/technical-stack/","title":"Technical Stack","text":"<p>This project leverages a variety of technologies to support robust backend processing, a responsive frontend, and scalable cloud infrastructure, all designed to help Red Light Ventures manage and optimize events through data-driven insights.</p>"},{"location":"introduction/technical-stack/#backend","title":"Backend","text":"<ul> <li>Django (Python): Serves as the primary backend framework, handling server-side logic, API development, and integration with AWS services. Key responsibilities include:</li> <li>API Development: Provides RESTful endpoints for frontend communication.</li> <li>User Authentication: Manages secure access control for different user roles.</li> <li>Event Scheduling &amp; Business Logic: Contains core business functions, such as ticketing rules, scheduling algorithms, and pricing calculations.</li> </ul>"},{"location":"introduction/technical-stack/#frontend","title":"Frontend","text":"<ul> <li>React (JavaScript): Creates a dynamic and responsive UI for managing events. Key libraries and tools include:</li> <li>State Management: Uses [insert any specific state management library, e.g., Redux or Context API] to manage complex states, such as ticket inventory and user preferences.</li> <li>Data Visualization: [List any specific libraries here, e.g., D3.js or Chart.js, if applicable] for rendering insights like ticket sales trends.</li> </ul>"},{"location":"introduction/technical-stack/#cloud-infrastructure","title":"Cloud Infrastructure","text":"<ul> <li>AWS SageMaker: Manages training, tuning, and deployment of machine learning models for tasks like ticket pricing predictions and attendance forecasting. Django connects to SageMaker models via [API Gateway / direct SDK integration], allowing secure interaction with deployed models.</li> <li>AWS DynamoDB: A NoSQL database to store high-volume data like event records, ticket inventories, and booking history. This choice enables fast, scalable access and is well-suited to Red Light Ventures\u2019 needs for low-latency operations.</li> <li>AWS S3: Stores static assets such as images, marketing media, and data backups. S3 also holds any exported analytics reports that may be shared with the client.</li> <li>AWS EC2: Hosts the Django backend, providing a reliable environment for production deployment. EC2 instances are configured for scalability and are monitored for performance.</li> </ul>"},{"location":"introduction/technical-stack/#additional-technologies","title":"Additional Technologies","text":"<ul> <li>Python: Used for backend development, data processing, and machine learning pipelines.</li> <li>JavaScript, HTML, CSS: Core frontend technologies with React, enabling a highly interactive and responsive user experience.</li> </ul>"},{"location":"introduction/technical-stack/#local-development-tools","title":"Local Development Tools","text":"<ul> <li>Docker: Used for containerization to streamline development and testing environments (if applicable).</li> <li>Testing Libraries: [List specific libraries, e.g., Jest, PyTest, etc.] to help ensure code quality and robustness.</li> </ul> <p>This setup provides a clear pathway for data flow, security, and scalability, empowering Red Light Ventures with the tools to make data-driven decisions for event management.</p>"},{"location":"project-structure/folder-structure/","title":"Folder Structure","text":"<p>This section provides an overview of the main folders and files in the project, explaining their purpose and organization.</p>"},{"location":"project-structure/folder-structure/#root-directory","title":"Root Directory","text":"<ul> <li> <p>/RLM-docs: Documentation directory.</p> <ul> <li>/docs: Contains all documentation files organized into specific topics like API, AWS, database, deployment, and features.</li> <li>mkdocs.yml: Configuration file for generating the documentation site with MKDocs.</li> </ul> </li> <li> <p>/RLM_Booking_Main: Django project root.</p> <ul> <li>settings.py: Global settings for the Django project, including database configurations, middleware, and installed apps.</li> <li>urls.py: Defines URL routing for the project.</li> <li>wsgi.py / asgi.py: Interfaces for serving the application.</li> </ul> </li> <li> <p>/apps: Contains Django apps grouped by functionality.</p> <ul> <li>/artist_recommendation: App handling artist recommendations.<ul> <li>models.py: Defines database models.</li> <li>views.py: Manages HTTP responses for artist recommendation.</li> <li>urls.py: Routes URLs specific to artist recommendations.</li> </ul> </li> <li>/concert_performance: Manages data and views related to concert performance analysis.</li> <li>/event_management: Provides functionality for event tracking and management.</li> <li>/marketing_tools: App dedicated to marketing and promotional tools.</li> </ul> </li> <li> <p>/data_processing: Contains data processing services and utilities.</p> <ul> <li>services.py: Primary service functions for data processing.</li> <li>/utils: Helper scripts like <code>data_writer.py</code> and <code>progress_manager.py</code> for handling data output and tracking.</li> </ul> </li> <li> <p>/integrations: Manages external data sources and APIs.</p> <ul> <li>spotify_data_manager.py: Connects and manages data from Spotify.</li> <li>ticketmaster_to_csv.py: Handles integration with Ticketmaster API to retrieve and export data.</li> </ul> </li> <li> <p>/shared_services: Contains utilities and shared services for AWS and logging.</p> <ul> <li>aws_database_manager.py: Manages AWS database connections and interactions.</li> <li>geolocation.py: Provides geolocation services.</li> <li>logging_manager.py: Configures and manages logging across the project.</li> </ul> </li> <li> <p>/static: Stores static assets like CSS, JavaScript, and images for frontend rendering.</p> </li> <li> <p>/templates: HTML templates for frontend views.</p> <ul> <li>base.html: Base template for page structure.</li> <li>artist_recommendation/index.html: Specific template for the artist recommendation page.</li> </ul> </li> </ul> <p>Each folder has been organized to facilitate efficient development, testing, and deployment. For detailed explanations of each folder's purpose, refer to the Key Modules section.</p>"},{"location":"project-structure/key-modules/","title":"Key Modules","text":"<p>This section provides an overview of each main module and its purpose in the project. Modules are grouped by functionality to clarify their roles in the application. Each class and its methods are listed with a brief description. For even more specific information on the methods see the method docstrings and code comments.</p>"},{"location":"project-structure/key-modules/#data-processing-module","title":"Data Processing Module","text":""},{"location":"project-structure/key-modules/#description","title":"Description","text":"<p>Handles backend data processing tasks, such as data cleaning and formatting, which support app functionalities like recommendation and event tracking.</p>"},{"location":"project-structure/key-modules/#key-components","title":"Key Components","text":"<ul> <li>services.py: Main data processing functions.</li> <li>/utils: Supporting functions, including data writing and progress tracking.<ul> <li>data_writer.py: Helper class to scrape API data into a CSV. Takes in a filename and CSV headers; reads in any existing entries in a CSV and writes any new entries in that same CSV. read_existing_entries reads through the given csv and returns a list of items already inside. write_entry_to_csv writes in the entry if it is new; returns true if the entry to write was new and false if not.</li> <li>progress_manager.py: Helper class to track the progress of API scraping to minimize API calls. Takes in a json file of the last API call stored and the headers of the data retrieved. Has load_progress which loads the API call progress stored in the JSON file. Has save_progress to record the last API call's info in the JSON file for future use. Has a should_skip method which checks if a potential call has already been made to reduce API calls.</li> </ul> </li> </ul>"},{"location":"project-structure/key-modules/#frontend-module","title":"Frontend Module","text":""},{"location":"project-structure/key-modules/#description_1","title":"Description","text":"<p>The frontend module, defined within the <code>/static</code> and <code>/templates</code> folders, manages user interface elements like HTML, CSS, and JavaScript files, allowing users to interact with the backend data.</p>"},{"location":"project-structure/key-modules/#key-components_1","title":"Key Components","text":"<ul> <li>Templates: HTML templates that render frontend views. Organized by Django app aka \"feature\".</li> <li>Static Assets: CSS for styling and JavaScript for interactive elements.</li> </ul>"},{"location":"project-structure/key-modules/#database-models-module","title":"Database Models Module","text":""},{"location":"project-structure/key-modules/#description_2","title":"Description","text":"<p>Defines Django models that handle the database schema and structure for data storage across different apps.</p>"},{"location":"project-structure/key-modules/#key-components_2","title":"Key Components","text":"<ul> <li>models.py: Located in each app, it contains models defining the schema for artist recommendations, event management, concert performance, and marketing tools.</li> <li>migrations: Scripts to update database schema in response to changes in models.</li> </ul>"},{"location":"project-structure/key-modules/#aws-integration-module","title":"AWS Integration Module","text":""},{"location":"project-structure/key-modules/#description_3","title":"Description","text":"<p>Manages connections with AWS services for database storage, machine learning, and media handling.</p>"},{"location":"project-structure/key-modules/#key-components_3","title":"Key Components","text":"<ul> <li>aws_database_manager.py: Connects with AWS databases like DynamoDB and S3.</li> <li>geolocation.py: Uses AWS location services to provide geolocation capabilities.</li> <li>logging_manager.py: Manages logging configurations, storing logs as needed for AWS services.</li> </ul>"},{"location":"project-structure/key-modules/#api-and-integrations-module","title":"API and Integrations Module","text":""},{"location":"project-structure/key-modules/#description_4","title":"Description","text":"<p>This module manages data communication both within the project (frontend and backend interactions) and with external APIs (e.g., Spotify, Ticketmaster). It includes the setup for API endpoints defined within each app (such as <code>artist_recommendation</code>, <code>concert_performance</code>) and manages integrations for retrieving and processing data from external sources.</p>"},{"location":"project-structure/key-modules/#key-components_4","title":"Key Components","text":"<ul> <li>Endpoints: Defines API routes across various apps for internal data management, handling data for artist recommendations, event management, concert performance, and marketing tools.</li> <li>api_manager.py: A parent class that generalizes API setup, handling authentication, token management, and request processing for external services. Requires the base url for your API, an optional authentication type (i.e. Basic or Bearer), and any optional API credentials formatted in two string parameter dictionary where the keys might be something like [client_id, client_secret]. Has an authenticate method to authenticate your API connection based on authentication type (if specified). Has get_oath_token method which retrieves the oauth token using any client credentials. Has a refresh_token method to refresh the token if the current one is expired or invalid (for the APIs with temporary access tokens). </li> <li>spotify_data_manager.py: Manages data retrieval and updates from Spotify, providing artist data for recommendations and analytics.</li> <li>ticketmaster_to_csv.py: Manages data retrieval from Ticketmaster, used for event listings and ticket information.</li> </ul>"}]}